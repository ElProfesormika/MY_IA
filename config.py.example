"""
Configuration des APIs IA - FICHIER D'EXEMPLE

Copiez ce fichier en config.py et remplissez vos cl√©s API
OU utilisez des variables d'environnement (recommand√©)
"""

import os
from dotenv import load_dotenv

# Charger les variables d'environnement depuis .env
load_dotenv()

# ============================================
# üîë API MISTRAL (RECOMMAND√â - GRATUITE)
# ============================================
# Pour obtenir votre cl√© API Mistral :
# 1. Allez sur https://console.mistral.ai/
# 2. Cr√©ez un compte (gratuit)
# 3. Allez dans "API Keys"
# 4. Cr√©ez une nouvelle cl√©
# 5. Copiez la cl√© dans le fichier .env ou ici

MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY", "")  # Lire depuis variable d'environnement
# Exemple: MISTRAL_API_KEY = "votre_cle_mistral_ici"

# Mod√®le Mistral √† utiliser (gratuit)
MISTRAL_MODEL = os.getenv("MISTRAL_MODEL", "mistral-small-latest")  # ou "mistral-tiny-latest" pour plus rapide

# ============================================
# üîë API HUGGING FACE (ALTERNATIVE)
# ============================================
# Pour obtenir votre cl√© API Hugging Face :
# 1. Allez sur https://huggingface.co/settings/tokens
# 2. Cr√©ez un nouveau token (type: Read)
# 3. Copiez le token dans le fichier .env ou ici (commence par hf_)

HUGGINGFACE_API_KEY = os.getenv("HUGGINGFACE_API_KEY", "")

# üîó URL DE L'API HUGGING FACE (si vous utilisez Hugging Face)
HUGGINGFACE_API_URL = os.getenv("HUGGINGFACE_API_URL", "https://router.huggingface.co/models/google/flan-t5-base")

# Alternatives si le mod√®le ci-dessus ne fonctionne pas (d√©commentez celle qui fonctionne) :
# HUGGINGFACE_API_URL = "https://router.huggingface.co/models/google/flan-t5-base"
# HUGGINGFACE_API_URL = "https://api-inference.huggingface.co/models/google/flan-t5-large"
# HUGGINGFACE_API_URL = "https://router.huggingface.co/models/mistralai/Devstral-Small-2-24B-Instruct-2512"

